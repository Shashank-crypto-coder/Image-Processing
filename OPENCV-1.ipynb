{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebed9bc2",
   "metadata": {},
   "source": [
    "## Read, Write and Color Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6c605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#installing the package\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing cv2 module\n",
    "import cv2\n",
    "  \n",
    "# reading the image\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "  \n",
    "# showing the image\n",
    "cv2.imshow(\"img\",img)\n",
    "  \n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a9441d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversion of image from rgb to gray\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6730610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversion of image from rgb to hsv\n",
    "hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"hsv_image\",hsv)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef2f984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the image in gray mode\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\",0) #gray mode\n",
    "  \n",
    "# showing the image\n",
    "cv2.imshow(\"mode\",img)\n",
    "  \n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758f1d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the image in rgb mode\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\",1) #rgb mode\n",
    "  \n",
    "# showing the image\n",
    "cv2.imshow(\"mode\",img)\n",
    "  \n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa95f9c",
   "metadata": {},
   "source": [
    "**Split** - Split the multi channel into separate channels.\n",
    "\n",
    "**Function :**\n",
    "cv2.split()\n",
    "\n",
    "**Merge** - Single channel into multi channel image.\n",
    "\n",
    "**Function :**\n",
    "cv2.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f602ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the image\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\",1) #rbg mode\n",
    "#spliting into rgb channels\n",
    "b, g, r=cv2.split(img)\n",
    "# showing the original image\n",
    "cv2.imshow(\"Original\",img)\n",
    "#displaying different channels\n",
    "cv2.imshow(\"red\",r)\n",
    "cv2.imshow(\"green\",g)  \n",
    "cv2.imshow(\"blue\",b)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6255f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the r,g,b channels to form the original image again\n",
    "merge_image=cv2.merge([r,b,g])\n",
    "cv2.imshow(\"merged image\",merge_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb442558",
   "metadata": {},
   "source": [
    "## Applying Smoothening Techniques for Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d89ca",
   "metadata": {},
   "source": [
    "**Blurring:**\n",
    "\n",
    "* Blurring is commomnly used technique for image processing to remove noise.\n",
    "\n",
    "* It is generally used to eliminate high frequent content such as noise edges in the image.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1.It removes low intensity edges.\n",
    "\n",
    "2.It helps in smoothening the image.\n",
    "\n",
    "**Meaning:**\n",
    "\n",
    "* The goal is to use a low-filter to reduce the amount of noise and detail in an image.\n",
    "\n",
    "* Each pixel in the image is mixed in with its surrounding pixel intensities.\n",
    "\n",
    "**Various methods for Blurring :**\n",
    "\n",
    "cv2.blur()\n",
    "\n",
    "cv2.GaussianBlur()\n",
    "\n",
    "cv2.medianBlur()\n",
    "\n",
    "cv2.bilateralFilter()\n",
    "\n",
    "**Averaging :**\n",
    "\n",
    "* In this techniques ,it calculate the average of all the pixels which are under kernel area and replace central element with calculated average\n",
    "\n",
    "**Function :**\n",
    "\n",
    "cv2.blur(img,kernel_size) and cv2.boxFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3569105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import numpy as np #used to work with image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6c754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the image\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600)) #resizing the image\n",
    "\n",
    "#blur the image\n",
    "blur=cv2.blur(img,(5,5))#mentioning a kernel of size 5x5\n",
    "\n",
    "cv2.imshow(\"Original_Image\",img)\n",
    "cv2.imshow(\"blurred_image\",blur) #the pixel intensity will be even\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38fd793",
   "metadata": {},
   "source": [
    "**Gaussian Blur :**\n",
    "\n",
    "* Image may contain various types of noise because of camera sensor it basically eliminate high frequency(noise edges) content from the image so edges are slightly blurred in the operation.\n",
    "\n",
    "* The Edges also get smoothen here.\n",
    "\n",
    "**Function:**\n",
    "\n",
    "cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4617994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the image\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))  #resizing the image\n",
    "\n",
    "#blurring the image\n",
    "Gaussian_blur=cv2.GaussianBlur(img,(5,5),0)  #using a kernel of size 5x5\n",
    "\n",
    "cv2.imshow(\"Original_Image\",img)\n",
    "cv2.imshow(\"Gaussian_image\",Gaussian_blur) #the pixel intensity will be even and The Edges also get smoothen here\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f7622",
   "metadata": {},
   "source": [
    "**Median Blur :**\n",
    "\n",
    "* Quite similar to Gaussian Blur.\n",
    "\n",
    "* It takes median of all the pixels under kernel area and center element is replaced with this median value.\n",
    "\n",
    "* It is Extremely effective for salt and pepper noise in image.\n",
    "\n",
    "**Function:**\n",
    "\n",
    "cv2.medianBlur(img,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc89f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the image\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))  #resizing the image\n",
    "\n",
    "#blurring the image\n",
    "median_blur=cv2.medianBlur(img,5)  #using a kernel of size 5x5\n",
    "\n",
    "cv2.imshow(\"Original_Image\",img)\n",
    "cv2.imshow(\"median_blur\",median_blur) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d918a42",
   "metadata": {},
   "source": [
    "## Image Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec1528",
   "metadata": {},
   "source": [
    "* Image filtering is the process of modifying the image by channging the shades or colors of the pixels.\n",
    "\n",
    "* It can also increasing brightness and contrast.\n",
    "\n",
    "**Types:**\n",
    "    \n",
    "1: Bilateral Filter\n",
    "\n",
    "2: Box Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c880688",
   "metadata": {},
   "source": [
    "**1) BilateralFilter :**\n",
    "\n",
    "->It can reduce unwanted noise very well while keeping edges.\n",
    "\n",
    "**Function:**\n",
    "\n",
    "cv2.bilateralFilter(img,9,75,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea06766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the image\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))  #resizing the image\n",
    "\n",
    "#blurring the image\n",
    "bilateral_filter=cv2.bilateralFilter(img,9,75,75)  #using a kernel of size 9x9,color range and color space\n",
    "\n",
    "cv2.imshow(\"Original_Image\",img)\n",
    "cv2.imshow(\"bilateral_filter\",bilateral_filter) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90219bba",
   "metadata": {},
   "source": [
    "**2) Box Filter :**\n",
    "\n",
    "->It is similar to Average filtering(bluring)\n",
    "\n",
    "**Function :**\n",
    "\n",
    "cv2.boxfilter(img,0,(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a382ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the image\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))  #resizing the image\n",
    "\n",
    "#blurring the image\n",
    "box_filter=cv2.boxFilter(img,0,(7,7))\n",
    "\n",
    "cv2.imshow(\"Original_Image\",img)\n",
    "cv2.imshow(\"box_filter\",box_filter) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240ab1c",
   "metadata": {},
   "source": [
    "## Edge Detection from image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25de526",
   "metadata": {},
   "source": [
    "**Edge Detection :**\n",
    "\n",
    "* Edges are defined as sudden and significant changes in the intesity of the image.\n",
    "* This changes will happen between the boundaries of objects in a image.\n",
    "\n",
    "*Steps in Edge Detection :*\n",
    "* Input image\n",
    "* Images Smoothening\n",
    "* Edge point Detection\n",
    "* Edge Location\n",
    "* Output\n",
    "\n",
    "*Image Smoothening :*\n",
    "* Remove noise from image.\n",
    "* Remove and supress the noise of image without altering quality of the image.\n",
    "\n",
    "*Edge Detection:*\n",
    "* Edges are detected through identifying the sudden changes in the intensity,even noise is all about sudden changes in the intensity.\n",
    "* Retain the edges of image object.\n",
    "\n",
    "*Edge Localization:*(linking the boundaries)\n",
    "* Edge localization is the process like thinning linking etc, are to carried out to locate the edges appropriately.\n",
    "\n",
    "**Types:**\n",
    "* Sobel Edge detector\n",
    "* Canny Edge detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe5cf0",
   "metadata": {},
   "source": [
    "#### **1)Sobel Edge Detector:**\n",
    "* The image is processed in the X and Y direction respectively.\n",
    "* This would result in the formation of new image, which actually is the sum of the X and Y edges of the images.\n",
    "* This approach work through calculation of Gradient of the image intensity at every pixel with in the image.\n",
    "\n",
    "*Calc:*\n",
    "\n",
    "* Sobel filter has two kernel(3x3 matrix)\n",
    "* One of them corresponds the X horizontal and other shall be used for the Y vertical.\n",
    "* These two kernels shall be convoluted with original image under the process through which the edges points are calculated with ease.\n",
    "* Kernal values shown below, that are fixed for Sobel filter and cannot altered.\n",
    "* The Gaussian filter play a vital role in the entire process.\n",
    "\n",
    "*Steps:*\n",
    "\n",
    "**Sobel Algorithm**\n",
    "*The Sobel algorithm can be summarized in four steps:\n",
    "* Converting the image into GrayScale.\n",
    "* Convolving the Gray image with Sobel-x filter.\n",
    "* Convolving the Gray image with Sobel-y filter.\n",
    "* Calculating the gradient magnitude and direction.\n",
    "\n",
    "*Sobel x:*\n",
    "\n",
    "[1 2 1]T  x  [-1 0 1] = [[-1,0,1][-2,0,2][-1,0,1]]\n",
    "\n",
    "*1D Gaussian filter X x-derivative = sobel-x*\n",
    "\n",
    "*Sobel y:*\n",
    "\n",
    "[-1 0 1]T  x  [1 2 1] = [[-1,-2,-1][0,0,0][1,2,1]]\n",
    "\n",
    "*y-derivative X 1D Gaussian filter = sobel-y*\n",
    "\n",
    "\n",
    "**Function:**\n",
    "\n",
    "Sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "Sobely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "Laplacian=cv2.Laplacian(img,cv2_64F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa078cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray_image\",gray)\n",
    "\n",
    "sobelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "cv2.imshow(\"Sobelx_of_rgb_image\",sobelx)\n",
    "\n",
    "sobelx=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=5)\n",
    "cv2.imshow(\"Sobelx_of_gray_image\",sobelx)\n",
    "\n",
    "sobely=cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=5)\n",
    "cv2.imshow(\"Sobely_of_gray_image\",sobely)\n",
    "\n",
    "laplacian=cv2.Laplacian(gray,cv2.CV_64F)\n",
    "cv2.imshow(\"laplacian\",laplacian)\n",
    "\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d520070",
   "metadata": {},
   "source": [
    "**2)Canny Edge Detector:**\n",
    "* Canny edge detection is a technique to extract useful structural information from different vision objects and dramatically reduce the amount of data to be processed.It has been widely applied in various computer vision systems.\n",
    "\n",
    "**Canny Algorithm:**\n",
    "\n",
    "* Input image -> Gray scale image\n",
    "* Noise Reduction \n",
    "\n",
    "         ->Operate with Gaussian Blur - its help to remove the noise of the input image for the further processing to be     smooth.\n",
    "     \n",
    "* Intensity Gradient Calculation:\n",
    "\n",
    "         -> Operate on it sobel filter to be used in this process.\n",
    "         \n",
    "         -> Calculate sudden intensity change with help of sobel operator.\n",
    "         \n",
    "         -> G=(Gx^2 + Gy^2)^2\n",
    "         \n",
    "* Non-Max Suppression:\n",
    "\n",
    "          -> Gradient magnitude operators - obtain thick edges.\n",
    "          \n",
    "          -> This process going to getting a right edges from the available image.\n",
    "          \n",
    "* Thresholding\n",
    "* EdgeTracking\n",
    "\n",
    "**Function:**\n",
    "\n",
    "cv2.Canny(Blur,100,200) #Threshold low(100) and Threshold high(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bd2056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray_image\",gray)\n",
    "\n",
    "blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "canny=cv2.Canny(blur,100,200)\n",
    "cv2.imshow(\"Canny_edges_for_gray_image\",canny)\n",
    "\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca9c96",
   "metadata": {},
   "source": [
    "* Result of Canny edge detection is same for both Gray Scale image as well as RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f73ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "#cv2.imshow(\"img\",img)\n",
    "\n",
    "blur=cv2.GaussianBlur(img,(5,5),0)\n",
    "canny=cv2.Canny(blur,100,200)\n",
    "cv2.imshow(\"Canny_edges_for_color_image\",canny)\n",
    "\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e75ac1",
   "metadata": {},
   "source": [
    "## Morphological Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71780ca",
   "metadata": {},
   "source": [
    "**Different Morphological Operations :**\n",
    "* Erosion\n",
    "* Dilation\n",
    "* Opening\n",
    "* Closing\n",
    "\n",
    "**Morphological Operation :**\n",
    "* Morphological Operation used for extracting image components that are helpful for description and representation of the shape of a region.\n",
    "* Morphological operations are the fundamental task are depends on the image shape.\n",
    "* It typically takes place on binary image or Gray Scale image.\n",
    "\n",
    "*Required data source:*\n",
    "* Input image\n",
    "* Structure component or kernel\n",
    "\n",
    "*Basic Morphological operation:*\n",
    "* Erosion - decreasing the shape of the forground\n",
    "* Dilation - increasing the shape of the foreground\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab1ee5",
   "metadata": {},
   "source": [
    "**1)Dilation :**\n",
    "* Its a technique to expand the image.\n",
    "* It add the number of pixel of the boundaries of the image.\n",
    "* Dilation can be controlled with structuring element,structuring element is a matrix of 0s and 1s.\n",
    "* Dilation expands the whites i.e 1s and reduces 0s.\n",
    "\n",
    "*Structuring element:*\n",
    "* Size and shape of structuring element define how many numbers of the pixel should be added or removed from the object of the image.\n",
    "\n",
    "**2)Erosion :**\n",
    "* It is a technique where we shorten the image.\n",
    "* It reduce the number of pixel to the boundaries of the image.\n",
    "* The Structural element is controlling it.\n",
    "* The Structural element is a matrix 0f 0s and 1s.\n",
    "* Erosion expands the blacks i.e 0s and reduces 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe9428f",
   "metadata": {},
   "source": [
    "**Morphology Transform :**\n",
    "* Opening\n",
    "* Closing\n",
    "\n",
    "**1)Opening Morphology :**\n",
    "* Opening operation is uesd for removing internal noise in an image.\n",
    "* Opening is erosion operation followed by dilation operation.\n",
    "\n",
    "**2)Closing Morphology :**\n",
    "* It is defined simply as a dilation followed by an erosion using the same structure element used in the opening operation.\n",
    "\n",
    "**Morphological Gradient :**\n",
    "* It is a difference between dilation and erosion of an image.\n",
    "* The result will be look like the outline of the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a803c",
   "metadata": {},
   "source": [
    "**Function**\n",
    "\n",
    "*Dilation:*\n",
    "cv2.dilate(img,kernel)\n",
    "\n",
    "*Erosion:*\n",
    "cv2.erode(img,kernel)\n",
    "\n",
    "*Opening:*\n",
    "cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)\n",
    "\n",
    "*Closing:*\n",
    "cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcaf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"cherry.jfif\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "dilation=cv2.dilate(gray,kernel)\n",
    "cv2.imshow(\"dilation\",dilation)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461433e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"cherry.jfif\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "erosion=cv2.erode(gray,kernel)\n",
    "cv2.imshow(\"Erosion\",erosion)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82920bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"cherry.jfif\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "morphology_open=cv2.morphologyEx(gray,cv2.MORPH_OPEN,kernel)  #reduces internal noise\n",
    "cv2.imshow(\"morphology_open\",morphology_open)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"cherry.jfif\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "morphology_close=cv2.morphologyEx(gray,cv2.MORPH_CLOSE,kernel)  #reduces internal noise\n",
    "cv2.imshow(\"morphology_close\",morphology_close)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e51d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"cherry.jfif\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "#cv2.imshow(\"img\",img)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray_image\",gray)\n",
    "\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "morphology_gradient=cv2.morphologyEx(gray,cv2.MORPH_GRADIENT,kernel) \n",
    "cv2.imshow(\"morphology_gradient\",morphology_gradient)\n",
    "# waiting using waitKey method\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf1f84",
   "metadata": {},
   "source": [
    "### Different Thresholding Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29ad2c",
   "metadata": {},
   "source": [
    "**Threshold Techniques :**\n",
    "* Its is one of the image segementation techniques - we extract the foreground from the background\n",
    "* It is the popular segmentation techniques.\n",
    "* It is used to separate an object from its background.\n",
    "* This technique can be done by using image pixel value (pixel intensity).\n",
    "\n",
    "**Process :**\n",
    "* The Process of thresholding comparing each pixel value of the image (pixel Intensity) to specified threshold.\n",
    "* This divides all the pixels of input into groups.\n",
    "* Pixel Intensity value < Threshold value => black\n",
    "* Pixel Intensity value > Threshold value => white"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4e04e",
   "metadata": {},
   "source": [
    "**Simple Thresholding :**\n",
    "* The basic thresholding technique in binary thresholding for every pixel, the same threshold value is applied.\n",
    "* If the pixel value smaller than the threshold value :\n",
    "        -> It is set to zero(0)\n",
    "        -> otherwise it is set to maximum value\n",
    "        \n",
    "**Method:**\n",
    "* cv2.THRESH_BINARY\n",
    "* cv2.THRESH_BINARY_INV\n",
    "* cv2.THRESH_TRUNC\n",
    "* cv2.THRESH_TOZERO\n",
    "* cv2.THRESH_TOZERO_INV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faea52c",
   "metadata": {},
   "source": [
    "**cv2.THRESH_BINARY:**\n",
    "\n",
    "    * if pixel value>threshold value\n",
    "        ->set value to 255\n",
    "      else\n",
    "          ->set to 0\n",
    "**Function:**\n",
    "cv2.threshold(img,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.threshold(img,threshold_value,max_value,cv2.THRESH_BINARY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687f1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "r,thresh1=cv2.threshold(img,125,255,cv2.THRESH_BINARY)\n",
    "r,thresh2=cv2.threshold(img,125,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresh_binary\",thresh1)\n",
    "cv2.imshow(\"Thresh_binary_inv\",thresh2)\n",
    "#cv2.imshow(\"original_image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20085d7f",
   "metadata": {},
   "source": [
    "**cv2.THRESH_TRUNC:**\n",
    "\n",
    "    * if pixel value>threshold value\n",
    "        ->set value to threshold value\n",
    "      else\n",
    "          ->set to 0\n",
    "**Function:**\n",
    "cv2.threshold(img,120,255,cv2.THRESH_TRUNC)\n",
    "\n",
    "cv2.threshold(img,threshold_value,max_value,cv2.THRESH_TRUNC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4582ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "r,thresh3=cv2.threshold(img,125,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow(\"Thresh_trunc\",thresh3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935dd95",
   "metadata": {},
   "source": [
    "**cv2.THRESH_TOZERO:**\n",
    "\n",
    "    * if pixel value>threshold value\n",
    "        ->no change in pixel value\n",
    "      else\n",
    "          ->set to 0\n",
    "**Function:**\n",
    "cv2.threshold(img,120,255,cv2.THRESH_TOZERO)\n",
    "\n",
    "cv2.threshold(img,threshold_value,max_value,cv2.THRESH_TOZERO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "120c37a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "r,thresh4=cv2.threshold(img,125,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow(\"Thresh_toZero\",thresh4)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733ec00",
   "metadata": {},
   "source": [
    "**cv2.THRESH_TOZERO_INV:**\n",
    "\n",
    "    * if pixel value>threshold value\n",
    "        ->set to 0\n",
    "      else\n",
    "          ->no change in pixel value\n",
    "**Function:**\n",
    "cv2.threshold(img,120,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.threshold(img,threshold_value,max_value,cv2.THRESH_TOZERO_INV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2565bfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(600,600))\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh5=cv2.threshold(img,125,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow(\"Thresh_toZero_inv\",thresh5)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0dcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
