{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42acfcf1",
   "metadata": {},
   "source": [
    "### Inserting Shapes and Texts into Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea18c51",
   "metadata": {},
   "source": [
    "**Opencv drawing function:**\n",
    "* We can draw the various shapes on an image such as circle,rectangle,line etc.\n",
    "* It is used when we want to highlight any object in the input image.Opencv provides functions for each shape.\n",
    "\n",
    "**Functions**\n",
    "* cv2.circle()\n",
    "* cv2.rectangle()\n",
    "* cv2.line()\n",
    "* cv2.putText()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef6e6c",
   "metadata": {},
   "source": [
    "**Draw Circle**\n",
    "cv2.circle(img,center,radius,color,thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725f58fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "cv2.circle(img,(180,170),80,(0,255,0),7) #(0,255,0) - BGR channel we get a green cicle here.\n",
    "cv2.imshow(\"Cicle\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ffc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "cv2.circle(img,(180,170),80,(56,25,80),7) \n",
    "cv2.imshow(\"Cicle\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78660834",
   "metadata": {},
   "source": [
    "**Draw Rectangle** cv2.rectangle(img,pt1,pt2,color,thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6bdb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "cv2.rectangle(img,(30,70),(200,270),(0,255,255),7) \n",
    "cv2.imshow(\"Rectangle\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca21e32",
   "metadata": {},
   "source": [
    "**Draw Line** cv2.line(img,pt1,pt2,color,thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6520a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "cv2.line(img,(30,70),(200,270),(255,5,255),7) \n",
    "cv2.imshow(\"Line\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82757b14",
   "metadata": {},
   "source": [
    "**Write text on the Image**\n",
    "\n",
    "**function:** cv2.putText(img,text,org,font,font_size,color,thickness)\n",
    "* org-origin:text starting point coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8881b628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,\"OpenCV\",(10,200),font,1,(0,255,235),6)\n",
    "cv2.imshow(\"Text on image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9f79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((400,400,3),np.uint8)\n",
    "cv2.imshow(\"Dark image\",img)\n",
    "font=cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,\"OpenCV\",(10,200),font,1,(0,255,235),6)\n",
    "cv2.imshow(\"Text on image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d629658f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "font=cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.putText(img,\"OpenCV\",(10,200),font,1,(0,255,235),6)\n",
    "cv2.imshow(\"Text on image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6756b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "font=cv2.FONT_HERSHEY_COMPLEX\n",
    "cv2.circle(img,(250,250),80,(0,0,255),7) \n",
    "cv2.imshow(\"Cicle on image\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038bf866",
   "metadata": {},
   "source": [
    "### Playing Video In Reverse Mode Using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6137e2e",
   "metadata": {},
   "source": [
    "**How to play video in reverse mode:**\n",
    "\n",
    "* Opencv library can be used to perform multiple operations on videos.\n",
    "\n",
    "* Take a video as input and play it in a reverse mode by breaking the video into frame by frame and simultaneously store that frame in the list.\n",
    "\n",
    "* After getting list of frames we perform iteration over the frames. For playing video in reverse mode,\n",
    "\n",
    "* we need only to iterate reverse in the list of frames. Use reverse method of the list for reversing the order of frames in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91112228",
   "metadata": {},
   "source": [
    "**Basic algorithm to capture video in opencv**\n",
    "\n",
    "* Use cv2.VideoCapture() to get a video capture object for the camera.\n",
    "* Setup infinite while loop and use the Read() method to read frames using the above created object.\n",
    "* Use cv2.imshow method to show the frames in the video.\n",
    "* Break the looping with help of clicking specify key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c39922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for accessing the camera\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    res,vid=cap.read()\n",
    "    cv2.imshow(\"frame\",vid)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord(\"q\"): #0xFF=cutoff\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206f2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for playing a video\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(\"SrisailamDam.mp4\")\n",
    "res,vid_frame=cap.read()\n",
    "count=0\n",
    "frame_list=[]\n",
    "while(res == True):\n",
    "    res,vid_frame=cap.read()\n",
    "    \n",
    "    frame_list.append(vid_frame)\n",
    "    count+=1\n",
    "    \n",
    "frame_list.pop() #since last frame that will be stored in list is None(when the condition becomes False)\n",
    "#So we need to clear that None \n",
    "for frame in frame_list:\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69657f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for reversing a video\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(\"SrisailamDam.mp4\")\n",
    "res,vid_frame=cap.read()\n",
    "count=0\n",
    "frame_list=[]\n",
    "while(res == True):\n",
    "    res,vid_frame=cap.read()\n",
    "    \n",
    "    frame_list.append(vid_frame)\n",
    "    count+=1\n",
    "    \n",
    "frame_list.pop() #since last frame that will be stored in list is None(when the condition becomes False)\n",
    "#So we need to clear that None \n",
    "for frame in frame_list:\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "frame_list.reverse()\n",
    "for frame in frame_list:\n",
    "    cv2.imshow(\"reverse mode\",frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7836ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for saving every frame\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(\"SrisailamDam.mp4\")\n",
    "res,vid_frame=cap.read()\n",
    "count=0\n",
    "frame_list=[]\n",
    "while(res == True):\n",
    "    cv2.imwrite(\"frame%d.jpg\" %count ,vid_frame )\n",
    "    res,vid_frame=cap.read()\n",
    "    frame_list.append(vid_frame)\n",
    "    count+=1\n",
    "    \n",
    "frame_list.pop()\n",
    "for frame in frame_list:\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d751f",
   "metadata": {},
   "source": [
    "### Optical Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4990a1f",
   "metadata": {},
   "source": [
    "* OCR - Computer can read the text same as we do.\n",
    "* OCR is technique of reading or grabbing text from printed or scanned photos.\n",
    "* Handwritten images are converted into digital form that can be editable and searchable.\n",
    "\n",
    "**Tesseract OCR:**\n",
    "* Tesseract is an open source text recognition engine.\n",
    "* It can be used directly or using an API to extract printed text from images.It support a wide variety of languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c50851",
   "metadata": {},
   "source": [
    "Sample OCR Script:\n",
    "\n",
    "* Import open source library for computer vision Reading the image\n",
    "* Resize the image if needed\n",
    "* Display the original image\n",
    "* Display the windows infinitely\n",
    "* Close all the windows\n",
    "\n",
    "Converting the image into string\n",
    "\n",
    "* Need pytesseract\n",
    "* Set the tesseract path in the code\n",
    "* Convert an image to string\n",
    "\n",
    "Create audio file(Text to Audio)\n",
    "\n",
    "* gTTS Is a python library with Google Translates Text -to- Speech API.\n",
    "* Install: command pip install gtts\n",
    "* Import necessary libraries\n",
    "* Set tesseract path\n",
    "* Image reading\n",
    "* Grab the text from image using pytesseract\n",
    "* Set the language\n",
    "* Convert the text to audio\n",
    "* Save the audio\n",
    "* Play the audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6faba",
   "metadata": {},
   "source": [
    "### Histogram Equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52e3e4",
   "metadata": {},
   "source": [
    "**Image Histogram:**\n",
    "* Histogram is graph plotting the frequency of occurrence of different color intensity in the image.\n",
    "* So if it is a gray scale image it will look something like this:\n",
    "    * Darker intensity - 0 (black)\n",
    "    * Strongest intensity - 1 (white)\n",
    "    \n",
    "**Histogram Equalization:**\n",
    "* It is a method in image processing of contrast adjustment using image histogram.\n",
    "* Used to increase the contrast of the image.\n",
    "* In this method usually increase the contrast of the image,especially when the usable data of the image is represented by close contrast values.Through this adjustment, the intensities can be better distributed on the Histogram.\n",
    "* The method is useful in images with backgrounds and foregrounds that are both bright or both dark.\n",
    "\n",
    "**Function:**\n",
    "*cv2.equalizeHist(img)*\n",
    "\n",
    "**Parameter:**\n",
    "* Gray Level (rK)\n",
    "* No.of pixel (nK)\n",
    "* Probability Distribution Function (PDF=nK/n)\n",
    "* Cumulative Distribution Function (CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545bdadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\",0)\n",
    "img=cv2.resize(img,(500,500))\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "equ=cv2.equalizeHist(img)\n",
    "cv2.imshow(\"Equalized Image\",equ)\n",
    "image=np.hstack((img,equ))\n",
    "cv2.imshow(\"Merged Image\",image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46e7a2",
   "metadata": {},
   "source": [
    "**Adaptive Histogram Equalization:**\n",
    "\n",
    "**Function:**\n",
    "*cv2.createCLAHE(cliplimit=5)*\n",
    "* CLAHE - Contrast Limiting Adaptive Histogram Equalization.\n",
    "\n",
    "**Parameters:**\n",
    "* clipLimit-This parameter sets the threshold for contrasting limiting.The default value is 40.\n",
    "* tileGridSize - This sets the no.of tiles in the row and column.By default this is 8x8.It is used while the image is divided into tiles for applying CLAHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fefe3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"PeacockFeather-1.jpg\")\n",
    "img=cv2.resize(img,(500,500))\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "\n",
    "clahe=cv2.createCLAHE(clipLimit=5)\n",
    "final_img=clahe.apply(img)\n",
    "cv2.imshow(\"Final Image\",final_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4889a6",
   "metadata": {},
   "source": [
    "### Real Time Multi Color Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f8d61",
   "metadata": {},
   "source": [
    "**Color Detection:**\n",
    "* Color detection is the process of detecting the name of any color.\n",
    "* The computer can recognize colors with the help of camera and OpenCV functions.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1.Camera Feed\n",
    "\n",
    "2.BGR to HSV conversion (HSV is mainly used for object detection and object tracking)\n",
    "\n",
    "3.Defining the range of colors being tracked\n",
    "\n",
    "4.Morphological Transformation (Smoothening the image and increasing the intensity of the Image)\n",
    "\n",
    "5.Contour/Filtering colours (Object tracking)\n",
    "\n",
    "6.Color detection output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef575c",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "\n",
    "* Step1: input- capture video through web cam\n",
    "* Step2: read the video stream in image frame\n",
    "* Step3: convert the image Frame in BGR to HSV\n",
    "* Step 4: define the range of each color and create the corresponding mask\n",
    "* Step5: morphological transform: dilation,remove the noise from the image\n",
    "* Step 6: bitwise_and between the image frame and mask is performed to specifically detect that particular color and discard others.\n",
    "* Step 7: Create contour for the individual colors to display the detected colored region distinguish.\n",
    "* Step 8: Output: Detection of the colors in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901cfb0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
